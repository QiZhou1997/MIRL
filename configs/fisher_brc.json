{
    "constant":{
        "env_name": "hopper",
        "dataset_name": "hopper-medium-v2"
    },
    "experiment":{
        "tag": "my_fbrc",
        "use_gpu": true,
        "seed": null,
        "base_log_dir": "~/data/mirl/fbrc",
        "log_level": "WARNING",
        "repeat": 5
    },
    "algorithm": {
        "sac": {
            "class": "OfflineRLAlgorithm",
            "kwargs": {
                "num_epochs": 1000,
                "batch_size": 256,
                "num_eval_steps":10000,
                "num_train_loops_per_epoch": 1000,
                "num_trains_per_train_loop": 1,
                "record_video_freq": -1,
                "silent": false
            }
        }
    },
    "environment": {
        "eval_env": {
            "class": "ContinuousVectorEnv",
            "kwargs": {
                "env_name": "$env_name",
                "n_env":10,
                "reward_scale": 1
            }
        },
        "video_env": {
            "class": "video_env",
            "kwargs": {
                "env_name": "$env_name"
            }
        }
    },
    "policy": {
        "policy": {
            "class": "gaussian_policy",
            "kwargs": {
                "env": "$eval_env",
                "hidden_layers": [256,256,256],
                "activation": "relu"
            }
        }
    },
    "value": {
        "qf": {
            "class": "FisherValue",
            "kwargs": {
                "env": "$eval_env",
                "hidden_layers": [256,256,256],
                "activation": "relu",
                "behavior_policy_kwargs":{
                    "hidden_layers": [256,256,256],
                    "activation": "relu"
                }
            } 
        },
        "qf_target": {
            "class": "FisherValue",
            "kwargs": {
                "env": "$eval_env",
                "hidden_layers": [256,256,256],
                "activation": "relu",
                "behavior_policy_kwargs":{
                    "hidden_layers": [256,256,256],
                    "activation": "relu"
                }
            } 
        }
    },
    "agent":{
        "agent": {
            "class": "FisherBRCAgent",
            "kwargs": {
                "env": "$eval_env",
                "policy": "$policy",
                "qf": "$qf",
                "qf_target": "$qf_target",
                "policy_lr": 3e-4,
                "qf_lr": 3e-4,
                "soft_target_tau": 5e-3,
                "use_automatic_entropy_tuning": true,
                "alpha_if_not_automatic": 0,
                "bp_lr_decay": 0.1,
                "bp_init_lr": 1e-3,
                "bp_train_steps": 1000000,
                "bp_lr_milestone":[800000, 900000],
                "fisher_reg": 0.1
            }
        }
    },
    "pool": {
        "pool": {
            "class": "OfflinePool",
            "kwargs": {
                "dataset_name": "$dataset_name",
                "pool_class": "SimplePool"
            }
        }
    },
    "collector": {
        "eval_collector": {
            "class": "simple_collector",
            "kwargs": {
                "env": "$eval_env",
                "agent": "$agent"
            }
        }
    }
}