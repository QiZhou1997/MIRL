{
    "constant": {
        "env_name": "cheetah",
        "target_entropy": -3,
        "depth_schedule": 1
    },
    "experiment": {
        "tag": "my_mbpo",
        "use_gpu": true,
        "seed": null,
        "base_log_dir": "~/data/mirl/mbpo",
        "log_level": "WARNING",
        "repeat": 5
    },
    "algorithm": {
        "sac": {
            "class": "DynaStyleAlgorithm",
            "kwargs": {
                "num_epochs": 150,
                "batch_size": 256,
                "num_eval_steps":10000,
                "num_train_loops_per_epoch": 1000,
                "num_expl_steps_per_train_loop": 1,
                "num_trains_per_train_loop": 20,
                "min_num_steps_before_training": 5000,
                "record_video_freq": -1,
                "silent": false,
                "real_data_ratio": 0.05,
                "train_model_freq": 250,
                "imagine_freq": 250
            }
        }
    },
    "environment": {
        "expl_env": {
            "class": "simple_env",
            "kwargs": {
                "env_name": "$env_name"
            }
        },
        "eval_env": {
            "class": "ContinuousVectorEnv",
            "kwargs": {
                "env_name": "$env_name",
                "n_env": 10,
                "reward_scale": 1
            }
        },
        "video_env": {
            "class": "video_env",
            "kwargs": {
                "env_name": "$env_name"
            }
        }
    },
    "policy": {
        "policy": {
            "class": "gaussian_policy",
            "kwargs": {
                "env": "$expl_env",
                "hidden_layers": [
                    256,
                    256
                ],
                "activation": "relu"
            }
        }
    },
    "value": {
        "qf": {
            "class": "ensemble_q_value",
            "kwargs": {
                "env": "$expl_env",
                "hidden_layers": [
                    256,
                    256
                ],
                "activation": "relu"
            }
        },
        "qf_target": {
            "class": "ensemble_q_value",
            "kwargs": {
                "env": "$expl_env",
                "hidden_layers": [
                    256,
                    256
                ],
                "activation": "relu"
            }
        }
    },
    "component": {
        "model": {
            "class": "PEModel",
            "kwargs": {
                "env": "$expl_env",
                "known": ["done"],
                "hidden_layers": [200,200,200,200],
                "activation": "swish",
                "connection": "simple",
                "reward_coef": 1,
                "bound_reg_coef": 2e-2,
                "weight_decay": [2.5e-5,5e-5,7.5e-5,7.5e-5,1e-4]
            }
        },
        "model_trainer": {
            "class": "PEModelTrainer",
            "kwargs": {
                "env": "$expl_env",
                "model": "$model",
                "lr": 1e-3,
                "init_model_train_step": 50000,
                "report_freq": 40,
                "max_not_improve": 20,
                "ignore_terminal_state": false
            }
        },
        "model_collector": {
            "class": "MBPOCollector",
            "kwargs": {
                "model": "$model",
                "policy": "$policy",
                "pool": "$pool", 
                "imagined_data_pool": "$imagined_data_pool",
                "depth_schedule": "$depth_schedule"
            }
        }
    },
    "agent": {
        "agent": {
            "class": "SAC_agent",
            "kwargs": {
                "env": "$expl_env",
                "policy": "$policy",
                "qf": "$qf",
                "qf_target": "$qf_target",
                "policy_lr": 3e-4,
                "qf_lr": 3e-4,
                "soft_target_tau": 5e-3,
                "use_automatic_entropy_tuning": true,
                "alpha_if_not_automatic": 0,
                "target_entropy": "$target_entropy"
            }
        }
    },
    "pool": {
        "pool": {
            "class": "ExtraFieldPool",
            "kwargs": {
                "env": "$expl_env",
                "max_size": 1e6,
                "compute_mean_std": true
            }
        },
        "imagined_data_pool": {
            "class": "simple_pool",
            "kwargs": {
                "env": "$expl_env",
                "max_size": 1e6
            }
        }
    },
    "collector": {
        "expl_collector": {
            "class": "simple_collector",
            "kwargs": {
                "env": "$expl_env",
                "agent": "$agent",
                "pool": "$pool"
            }
        },
        "eval_collector": {
            "class": "simple_collector",
            "kwargs": {
                "env": "$eval_env",
                "agent": "$agent"
            }
        }
    }
}